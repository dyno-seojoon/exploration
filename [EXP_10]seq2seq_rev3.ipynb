{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPV+RphYf1i7WyOLClcqTGS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 10. 프로젝트 : 단어 Level로 번역기 업그레이드하기"],"metadata":{"id":"Su5fDraV1Wg_"}},{"cell_type":"markdown","source":["글자 단위(Character-level) → 단어 단위(Word-level) 번역을 해보자"],"metadata":{"id":"0b0zb4Vq3fd5"}},{"cell_type":"markdown","source":["---\n","## Step 0. 시작 전 주요 라이브러리 및 데이터 호출"],"metadata":{"id":"_6vzZMrv1tXD"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"oXPShFnA52Rm","executionInfo":{"status":"ok","timestamp":1666705908737,"user_tz":-540,"elapsed":3133,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"outputs":[],"source":["import os\n","import re\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","import unicodedata\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Dropout\n","from tensorflow.keras.models import Model\n"]},{"cell_type":"code","source":[],"metadata":{"id":"QiX-f0Ih1iqu","executionInfo":{"status":"ok","timestamp":1666705909276,"user_tz":-540,"elapsed":546,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Google Drive - Colab  연동을 위한 라이브러리 Import\n","from google.colab import drive\n","drive.mount('/content/drive')\n","data_dir = '/content/drive/MyDrive/Exploration/data'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-IQH-Gxh4e3W","executionInfo":{"status":"ok","timestamp":1666705911655,"user_tz":-540,"elapsed":2393,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}},"outputId":"66237a47-986e-47d4-c4b3-008daadab2d3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["file_path = data_dir+'/seq2seq/fra.txt'\n","sentences = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n","print('전체 샘플의 수 :',len(sentences))\n","sentences.sample(5) #샘플 5개 출력"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"Un2dtxie46J6","executionInfo":{"status":"ok","timestamp":1666705913405,"user_tz":-540,"elapsed":1758,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}},"outputId":"86255c29-02bb-4df9-a008-34962236497c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 샘플의 수 : 197463\n"]},{"output_type":"execute_result","data":{"text/plain":["                                      eng  \\\n","125962   Spring will be here before long.   \n","74381           That's a very old saying.   \n","118898    No criminal charges were filed.   \n","128876  He convinced me of his innocence.   \n","9598                      Am I qualified?   \n","\n","                                                      fra  \\\n","125962                     Le printemps est pour bientôt.   \n","74381                          C'est un très vieil adage.   \n","118898  Aucune accusation criminelle n'a été enregistrée.   \n","128876                 Il m'a convaincu de son innocence.   \n","9598                 Est-ce que je réponds aux critères ?   \n","\n","                                                       cc  \n","125962  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n","74381   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n","118898  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n","128876  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n","9598    CC-BY 2.0 (France) Attribution: tatoeba.org #8...  "],"text/html":["\n","  <div id=\"df-50bb649d-3c02-4263-bf11-5c9c422458d5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>fra</th>\n","      <th>cc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>125962</th>\n","      <td>Spring will be here before long.</td>\n","      <td>Le printemps est pour bientôt.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n","    </tr>\n","    <tr>\n","      <th>74381</th>\n","      <td>That's a very old saying.</td>\n","      <td>C'est un très vieil adage.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","    <tr>\n","      <th>118898</th>\n","      <td>No criminal charges were filed.</td>\n","      <td>Aucune accusation criminelle n'a été enregistrée.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","    <tr>\n","      <th>128876</th>\n","      <td>He convinced me of his innocence.</td>\n","      <td>Il m'a convaincu de son innocence.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","    <tr>\n","      <th>9598</th>\n","      <td>Am I qualified?</td>\n","      <td>Est-ce que je réponds aux critères ?</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50bb649d-3c02-4263-bf11-5c9c422458d5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-50bb649d-3c02-4263-bf11-5c9c422458d5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-50bb649d-3c02-4263-bf11-5c9c422458d5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["del sentences['cc']\n","sentences.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"3BkDGhEGH2Vq","executionInfo":{"status":"ok","timestamp":1666705913407,"user_tz":-540,"elapsed":24,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}},"outputId":"0477bc26-2fc6-4faa-a790-7f3887f9cf45"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   eng         fra\n","0  Go.        Va !\n","1  Go.     Marche.\n","2  Go.  En route !\n","3  Go.     Bouge !\n","4  Hi.     Salut !"],"text/html":["\n","  <div id=\"df-d708fa34-bcda-486c-b24a-ca04950315c7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>fra</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Go.</td>\n","      <td>Marche.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Go.</td>\n","      <td>En route !</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Go.</td>\n","      <td>Bouge !</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d708fa34-bcda-486c-b24a-ca04950315c7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d708fa34-bcda-486c-b24a-ca04950315c7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d708fa34-bcda-486c-b24a-ca04950315c7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["---\n","## Step 1. 정제, 정규화, 전처리 (+토큰화)"],"metadata":{"id":"_cpBhu4K1-n_"}},{"cell_type":"markdown","source":["[참고] 글자 단위가 아닌 단어 번역을 위한 추가적인 전처리가 필요하다.\n","1. 구두점(Punctuation)을 단어와 분리\n","2. 소문자로 치환\n","3. 띄어쓰기 단위로 토큰화 수행"],"metadata":{"id":"x3LWf3XV2GOp"}},{"cell_type":"markdown","source":["전처리에 앞서, 사용 할 샘플의 양은 전체 데이터에서 33,000개이다."],"metadata":{"id":"nXCYjqG-K7UP"}},{"cell_type":"code","source":["# 사용 할 senteces\n","num_samples = 33000"],"metadata":{"id":"8Yt6yOFdINEN","executionInfo":{"status":"ok","timestamp":1666705913409,"user_tz":-540,"elapsed":24,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["전처리 함수 구현"],"metadata":{"id":"yKf-MBTAKqT_"}},{"cell_type":"code","source":["def to_ascii(s):\n","  # 프랑스어 악센트(accent) 삭제\n","  # 예시 : 'déjà diné' -> deja dine\n","  return ''.join(c for c in unicodedata.normalize('NFD', s)\n","                   if unicodedata.category(c) != 'Mn')\n","\n","def preprocess_sentence(sent):\n","  # 악센트 제거 함수 호출\n","  sent = to_ascii(sent.lower())\n","\n","  # 단어와 구두점 사이에 공백 추가.\n","  # ex) \"I am a student.\" => \"I am a student .\"\n","  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n","\n","  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환.\n","  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n","\n","  # 다수 개의 공백을 하나의 공백으로 치환\n","  sent = re.sub(r\"\\s+\", \" \", sent)\n","  return sent"],"metadata":{"id":"PRhALaWYIRwT","executionInfo":{"status":"ok","timestamp":1666705913410,"user_tz":-540,"elapsed":25,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 전처리 테스트\n","en_sent = u\"Have you had dinner?\"\n","fr_sent = u\"Avez-vous déjà diné?\"\n","\n","print('전처리 전 영어 문장 :', en_sent)\n","print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n","print('전처리 전 프랑스어 문장 :', fr_sent)\n","print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33RlIL7lIh1Z","executionInfo":{"status":"ok","timestamp":1666705913414,"user_tz":-540,"elapsed":29,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}},"outputId":"f7c611d8-20f2-43ba-c2aa-03e935ad8a2b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["전처리 전 영어 문장 : Have you had dinner?\n","전처리 후 영어 문장 : have you had dinner ?\n","전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n","전처리 후 프랑스어 문장 : avez vous deja dine ?\n"]}]},{"cell_type":"markdown","source":["훈련 시 사용할 레이블에 해당되는 출력 시퀀스를 따로 분리하여 저장한다.\n","\n","입력 시퀀스에는 시작을 의미하는 토큰인 <sos>를 추가하고,  \n","출력 시퀀스에는 종료를 의미하는 토큰인 <eos>를 추가한다."],"metadata":{"id":"LdGAETIqK3AR"}},{"cell_type":"code","source":["def load_preprocessed_data():\n","  encoder_input, decoder_input, decoder_target = [], [], []\n","\n","  with open(file_path, \"r\") as lines:\n","    for i, line in enumerate(lines):\n","      # source 데이터와 target 데이터 분리\n","      src_line, tar_line, _ = line.strip().split('\\t')\n","\n","      # source 데이터 전처리\n","      src_line = [w for w in preprocess_sentence(src_line).split()]\n","\n","      # target 데이터 전처리\n","      tar_line = preprocess_sentence(tar_line)\n","      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n","      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n","\n","      encoder_input.append(src_line)\n","      decoder_input.append(tar_line_in)\n","      decoder_target.append(tar_line_out)\n","\n","      if i == num_samples - 1:\n","        break\n","\n","  return encoder_input, decoder_input, decoder_target"],"metadata":{"id":"QsIjpjXYIiLJ","executionInfo":{"status":"ok","timestamp":1666705913416,"user_tz":-540,"elapsed":26,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n","print('인코더의 입력 :',sents_en_in[:5])\n","print('디코더의 입력 :',sents_fra_in[:5])\n","print('디코더의 레이블 :',sents_fra_out[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYmageNsIqF9","executionInfo":{"status":"ok","timestamp":1666705916320,"user_tz":-540,"elapsed":2929,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}},"outputId":"620992af-4371-40ab-b68d-69c3d76955a6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n","디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n","디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"]}]},{"cell_type":"markdown","source":["케라스 토크나이저를 통해 단어 집합을 생성, 정수 인코딩을 진행 후 이어서 패딩을 진행합니다."],"metadata":{"id":"-HtfAamvJyUe"}},{"cell_type":"code","source":["tokenizer_en = Tokenizer(filters=\"\", lower=False)\n","tokenizer_en.fit_on_texts(sents_en_in)\n","encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n","encoder_input = pad_sequences(encoder_input, padding=\"post\")\n","\n","tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n","tokenizer_fra.fit_on_texts(sents_fra_in)\n","tokenizer_fra.fit_on_texts(sents_fra_out)\n","\n","decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n","decoder_input = pad_sequences(decoder_input, padding=\"post\")\n","\n","decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n","decoder_target = pad_sequences(decoder_target, padding=\"post\")"],"metadata":{"id":"bo5ycVQLJiKM","executionInfo":{"status":"ok","timestamp":1666705919067,"user_tz":-540,"elapsed":2766,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n","print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n","print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCM5m9H1Jl9z","executionInfo":{"status":"ok","timestamp":1666705919068,"user_tz":-540,"elapsed":31,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}},"outputId":"22c54715-c81a-438c-ec27-de8c62bb4b1e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["인코더의 입력의 크기(shape) : (33000, 8)\n","디코더의 입력의 크기(shape) : (33000, 16)\n","디코더의 레이블의 크기(shape) : (33000, 16)\n"]}]},{"cell_type":"markdown","source":["단어 집합 크기에 대한 정의"],"metadata":{"id":"3o1kNvU2LhlJ"}},{"cell_type":"code","source":["src_vocab_size = len(tokenizer_en.word_index) + 1\n","tar_vocab_size = len(tokenizer_fra.word_index) + 1\n","print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5y1F5e1cJlzR","executionInfo":{"status":"ok","timestamp":1666705919069,"user_tz":-540,"elapsed":27,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}},"outputId":"fb469fba-3405-45de-9453-1eb30e87ae3c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["영어 단어 집합의 크기 : 4672, 프랑스어 단어 집합의 크기 : 8137\n"]}]},{"cell_type":"code","source":["src_to_index = tokenizer_en.word_index\n","index_to_src = tokenizer_en.index_word\n","tar_to_index = tokenizer_fra.word_index\n","index_to_tar = tokenizer_fra.index_word"],"metadata":{"id":"E0ffExniJlpZ","executionInfo":{"status":"ok","timestamp":1666705919070,"user_tz":-540,"elapsed":23,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["train/test를 분리하기 전 데이터를 무작위로 섞어준다."],"metadata":{"id":"XKhTqWBvLwg_"}},{"cell_type":"code","source":["indices = np.arange(encoder_input.shape[0])\n","np.random.shuffle(indices)\n","print('랜덤 시퀀스 :',indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9vDf-GQJleB","executionInfo":{"status":"ok","timestamp":1666705919070,"user_tz":-540,"elapsed":23,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}},"outputId":"383ac69e-1241-4481-9008-f2684269caf6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["랜덤 시퀀스 : [31336 21483  9349 ...   619 13729 28767]\n"]}]},{"cell_type":"code","source":["encoder_input = encoder_input[indices]\n","decoder_input = decoder_input[indices]\n","decoder_target = decoder_target[indices]"],"metadata":{"id":"SeqB6-B5JlSh","executionInfo":{"status":"ok","timestamp":1666705919071,"user_tz":-540,"elapsed":20,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Cv8TeuarJlF5","executionInfo":{"status":"ok","timestamp":1666705919071,"user_tz":-540,"elapsed":19,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["사용 할 samples 각각 30000 / 3000 개의 train / validation으로 분리하자"],"metadata":{"id":"v4R_U66sM5MB"}},{"cell_type":"code","source":["# Validation dat의 수\n","n_of_val = 3000"],"metadata":{"id":"a1FQwPaLJklZ","executionInfo":{"status":"ok","timestamp":1666705919072,"user_tz":-540,"elapsed":19,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"AxkygW8GM4Wj"}},{"cell_type":"code","source":["encoder_input_train = encoder_input[:-n_of_val]\n","decoder_input_train = decoder_input[:-n_of_val]\n","decoder_target_train = decoder_target[:-n_of_val]\n","\n","encoder_input_test = encoder_input[-n_of_val:]\n","decoder_input_test = decoder_input[-n_of_val:]\n","decoder_target_test = decoder_target[-n_of_val:]"],"metadata":{"id":"T61IhY-9JjAL","executionInfo":{"status":"ok","timestamp":1666705919073,"user_tz":-540,"elapsed":19,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n","print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n","print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n","print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n","print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n","print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nqpKZtwrJjuy","executionInfo":{"status":"ok","timestamp":1666705919073,"user_tz":-540,"elapsed":18,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}},"outputId":"07d2af8b-7120-4b2d-b2dd-8c50bdc93206"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 source 데이터의 크기 : (30000, 8)\n","훈련 target 데이터의 크기 : (30000, 16)\n","훈련 target 레이블의 크기 : (30000, 16)\n","테스트 source 데이터의 크기 : (3000, 8)\n","테스트 target 데이터의 크기 : (3000, 16)\n","테스트 target 레이블의 크기 : (3000, 16)\n"]}]},{"cell_type":"markdown","source":["---\n","## Step 2. 임베딩 층(Embedding layer) 사용하기"],"metadata":{"id":"InqKOqeA2vfD"}},{"cell_type":"markdown","source":["> 주의할 점은 인코더와 디코더의 임베딩 층은 서로 다른 임베딩 층을 사용해야 하지만,  \n","> 디코더의 훈련 과정과 테스트 과정(예측 과정)에서의 임베딩 층은 동일해야 합니다!"],"metadata":{"id":"tTW2ljFb3EUq"}},{"cell_type":"code","source":["embedding_dim = 64\n","hidden_units = 64"],"metadata":{"id":"bsMUZ_vkOIol","executionInfo":{"status":"ok","timestamp":1666705919074,"user_tz":-540,"elapsed":15,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# 인코더\n","encoder_inputs = Input(shape=(None,))\n","\n","enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n","enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n","encoder_lstm = LSTM(hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n","encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n","encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"],"metadata":{"id":"XvJz8LShOKGV","executionInfo":{"status":"ok","timestamp":1666705921791,"user_tz":-540,"elapsed":2731,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# 디코더\n","decoder_inputs = Input(shape=(None,))\n","\n","dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # 임베딩 층\n","dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n","dec_masking = Masking(mask_value=0.0)(dec_emb)\n","# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n","decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True) \n","# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n","decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n","\n","# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n","decoder_dense = Dense(tar_vocab_size, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)"],"metadata":{"id":"kk4kmuMkOMhg","executionInfo":{"status":"ok","timestamp":1666705924506,"user_tz":-540,"elapsed":2740,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["---\n","## Step 3. 모델 구현"],"metadata":{"id":"CO7amF4m3HCv"}},{"cell_type":"code","source":["# 모델의 입력과 출력을 정의.\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"],"metadata":{"id":"jNHHuJSfO5BO","executionInfo":{"status":"ok","timestamp":1666705924507,"user_tz":-540,"elapsed":42,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0zcUvZdO6RF","executionInfo":{"status":"ok","timestamp":1666705924508,"user_tz":-540,"elapsed":41,"user":{"displayName":"Seojoon Kang","userId":"03671467470939808326"}},"outputId":"53774d8a-3779-4472-c38c-722b4a6a4b9e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, None, 64)     299008      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, None, 64)     520768      ['input_2[0][0]']                \n","                                                                                                  \n"," masking (Masking)              (None, None, 64)     0           ['embedding[0][0]']              \n","                                                                                                  \n"," masking_1 (Masking)            (None, None, 64)     0           ['embedding_1[0][0]']            \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 64),         33024       ['masking[0][0]']                \n","                                 (None, 64),                                                      \n","                                 (None, 64)]                                                      \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, None, 64),   33024       ['masking_1[0][0]',              \n","                                 (None, 64),                      'lstm[0][1]',                   \n","                                 (None, 64)]                      'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, None, 8137)   528905      ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,414,729\n","Trainable params: 1,414,729\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["---\n","## Step 4. 모델 평가"],"metadata":{"id":"X6EYpl203Ikd"}},{"cell_type":"code","source":["stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n","\n","history = model.fit(\n","    x=[encoder_input_train, decoder_input_train],\n","    y=decoder_target_train,\n","    validation_data=([encoder_input_test, decoder_input_test],\n","                     decoder_target_test), batch_size=128, epochs=50, callbacks=[stop])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gi9PD1bcJkbS","outputId":"57af4b3c-bb25-4e9b-889b-c7ec05304ebd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]}]},{"cell_type":"code","source":["plt.style.use('seaborn')\n","graph = history.history\n","\n","acc = graph['acc']\n","val_acc = graph['val_acc']\n","loss = graph['loss']\n","val_loss = graph['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.figure(figsize=(15, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs, loss, 'r', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs, acc, 'r', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"GMq7PDUeTINn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","## Step 5. 번역기 확인"],"metadata":{"id":"zIpHYG_bRFcf"}},{"cell_type":"markdown","source":["테스트를 위한 모델 설계"],"metadata":{"id":"g_A4R7D2RP25"}},{"cell_type":"code","source":["# 인코더\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","# 디코더 설계 시작\n","# 이전 시점의 상태를 보관할 텐서\n","decoder_state_input_h = Input(shape=(hidden_units,))\n","decoder_state_input_c = Input(shape=(hidden_units,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","# 훈련 때 사용했던 임베딩 층을 재사용\n","dec_emb2 = dec_emb_layer(decoder_inputs)\n","\n","# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n","decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n","decoder_states2 = [state_h2, state_c2]\n","\n","# 모든 시점에 대해서 단어 예측\n","decoder_outputs2 = decoder_dense(decoder_outputs2)\n","\n","# 수정된 디코더\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs2] + decoder_states2)"],"metadata":{"id":"sKoFUkEiRXII"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["번역기의 테스트 동작을 위한 decode_sequence 함수 구현  \n","정수로 변환된 단어들을 텍스트 sequence로 변환하기 위함이다."],"metadata":{"id":"hsvHA0GMRhRf"}},{"cell_type":"code","source":["def decode_sequence(input_seq):\n","  # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n","  states_value = encoder_model.predict(input_seq)\n","\n","  # <SOS>에 해당하는 정수 생성\n","  target_seq = np.zeros((1,1))\n","  target_seq[0, 0] = tar_to_index['<sos>']\n","\n","  stop_condition = False\n","  decoded_sentence = ''\n","\n","  # stop_condition이 True가 될 때까지 루프 반복\n","  # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n","  while not stop_condition:\n","    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n","    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","    # 예측 결과를 단어로 변환\n","    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","    sampled_char = index_to_tar[sampled_token_index]\n","\n","    # 현재 시점의 예측 단어를 예측 문장에 추가\n","    decoded_sentence += ' '+sampled_char\n","\n","    # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n","    if (sampled_char == '<eos>' or\n","        len(decoded_sentence) > 50):\n","        stop_condition = True\n","\n","    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n","    target_seq = np.zeros((1,1))\n","    target_seq[0, 0] = sampled_token_index\n","\n","    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n","    states_value = [h, c]\n","\n","  return decoded_sentence"],"metadata":{"id":"a5MCRCyjRhxv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n","def seq_to_src(input_seq):\n","  sentence = ''\n","  for encoded_word in input_seq:\n","    if(encoded_word != 0):\n","      sentence = sentence + index_to_src[encoded_word] + ' '\n","  return sentence\n","\n","# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n","def seq_to_tar(input_seq):\n","  sentence = ''\n","  for encoded_word in input_seq:\n","    if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n","      sentence = sentence + index_to_tar[encoded_word] + ' '\n","  return sentence"],"metadata":{"id":"iRNCHyZZSik7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["샘플에서 임의의 인덱스에 해당하는 샘플들의 결과를 출력"],"metadata":{"id":"7FFEz4H7SldC"}},{"cell_type":"code","source":["for seq_index in [3, 50, 100, 300, 1001]:\n","  input_seq = encoder_input_train[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(input_seq)\n","\n","  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n","  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n","  print(\"번역문장 :\",decoded_sentence[1:-5])\n","  print(\"-\"*50)"],"metadata":{"id":"aVeSJhf_Srev"},"execution_count":null,"outputs":[]}]}